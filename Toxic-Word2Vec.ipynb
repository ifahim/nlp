{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction.\n",
    "\n",
    "These are some (modest) attempts at participating in Jigsaw's toxic comments classification problem. For now, I am not using any external data, only the training data given (which is limiting as it's a tiny dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gensim\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import re\n",
    "import string\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import h5py\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/toxicity_annotated_comments.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...  2002   \n",
       "1   4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  \n",
       "0       True  article  random  train  \n",
       "1       True     user  random  train  \n",
       "2      False  article  random   test  \n",
       "3       True  article  random  train  \n",
       "4       True  article  random   test  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159686"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = pd.read_csv('data/toxicity_annotations.tsv',  sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3989</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>1508</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>4020</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id  worker_id  toxicity  toxicity_score\n",
       "0  2232.0        723         0             0.0\n",
       "1  2232.0       4000         0             0.0\n",
       "2  2232.0       3989         0             1.0\n",
       "3  2232.0       3341         0             0.0\n",
       "4  2232.0       1574         0             1.0\n",
       "5  2232.0       1508         0             1.0\n",
       "6  2232.0        772         0             1.0\n",
       "7  2232.0        680         0             0.0\n",
       "8  2232.0        405         0             1.0\n",
       "9  2232.0       4020         1            -1.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.drop_duplicates(subset='rev_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159686"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.merge(scores, on='rev_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159686"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>2596</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>1642</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35367.0</td>\n",
       "      <td>`:In an interpreted language your source code ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>1408</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37330.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37346.0</td>\n",
       "      <td>`If they are ``indisputable`` then why does th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37675.0</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44377.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe co...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>1927</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...  2002   \n",
       "1   4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "5  35367.0  `:In an interpreted language your source code ...  2002   \n",
       "6  37330.0  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...  2002   \n",
       "7  37346.0  `If they are ``indisputable`` then why does th...  2002   \n",
       "8  37675.0  `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002   \n",
       "9  44377.0  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe co...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  worker_id  toxicity  toxicity_score  \n",
       "0       True  article  random  train        723         0             0.0  \n",
       "1       True     user  random  train        500         0             0.0  \n",
       "2      False  article  random   test       2596         0             1.0  \n",
       "3       True  article  random  train       1642         0             1.0  \n",
       "4       True  article  random   test        202         0             1.0  \n",
       "5       True  article  random    dev       1408         0             1.0  \n",
       "6       True  article  random  train        691         0             0.0  \n",
       "7       True  article  random  train       1108         0             0.0  \n",
       "8      False  article  random    dev        403         0             1.0  \n",
       "9       True  article  random  train       1927         0             2.0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['year', 'logged_in', 'split', 'ns', 'sample', 'worker_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35367.0</td>\n",
       "      <td>`:In an interpreted language your source code ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37330.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37346.0</td>\n",
       "      <td>`If they are ``indisputable`` then why does th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37675.0</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44377.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe co...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  toxicity  \\\n",
       "0   2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...         0   \n",
       "1   4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...         0   \n",
       "2   8953.0                          Elected or Electoral? JHK         0   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...         0   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...         0   \n",
       "5  35367.0  `:In an interpreted language your source code ...         0   \n",
       "6  37330.0  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...         0   \n",
       "7  37346.0  `If they are ``indisputable`` then why does th...         0   \n",
       "8  37675.0  `-NEWLINE_TOKENThis is not ``creative``.  Thos...         0   \n",
       "9  44377.0  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe co...         0   \n",
       "\n",
       "   toxicity_score  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             1.0  \n",
       "3             1.0  \n",
       "4             1.0  \n",
       "5             1.0  \n",
       "6             0.0  \n",
       "7             0.0  \n",
       "8             1.0  \n",
       "9             2.0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def mr_clean(comment):\n",
    "    comment = re.sub('NEWLINE_TOKEN', '', comment)\n",
    "    comment = re_tok.sub('', comment)             # remove punctuation\n",
    "    comment = re.sub('_', ' ', comment)\n",
    "    comment = re.sub( '\\s+', ' ', comment)\n",
    "    comment = comment.strip()\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment'] = df['comment'].apply(mr_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['toxic'] = df['toxicity_score'].apply(lambda x: int(x < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['toxicity', 'toxicity_score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.sort_values(['toxic'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>250290.0</td>\n",
       "      <td>Ed I am tired Anyway I certainly did not mean ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>608166.0</td>\n",
       "      <td>1 I dont think unreadable is that far off beam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>630630.0</td>\n",
       "      <td>On second thought why not instead provide a ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>682829.0</td>\n",
       "      <td>Youd think neonazis would have other business ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>749900.0</td>\n",
       "      <td>The Macedonian ORIGIN name is MonastirGreek na...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>761965.0</td>\n",
       "      <td>Nice work on this article folks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>790462.0</td>\n",
       "      <td>Sorry you send this message to the wrong user</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>856388.0</td>\n",
       "      <td>The Protocols isnt a conspiracy theory it is a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1171026.0</td>\n",
       "      <td>Id be interested to know why this page discuss...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1245501.0</td>\n",
       "      <td>I was with you until the last paragraph which ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rev_id                                            comment  toxic\n",
       "42    250290.0  Ed I am tired Anyway I certainly did not mean ...      1\n",
       "86    608166.0  1 I dont think unreadable is that far off beam...      1\n",
       "94    630630.0  On second thought why not instead provide a ne...      1\n",
       "104   682829.0  Youd think neonazis would have other business ...      1\n",
       "122   749900.0  The Macedonian ORIGIN name is MonastirGreek na...      1\n",
       "124   761965.0                    Nice work on this article folks      1\n",
       "133   790462.0      Sorry you send this message to the wrong user      1\n",
       "142   856388.0  The Protocols isnt a conspiracy theory it is a...      1\n",
       "195  1171026.0  Id be interested to know why this page discuss...      1\n",
       "207  1245501.0  I was with you until the last paragraph which ...      1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['toxic']==1].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df.toxic\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.1, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143717"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15969"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.to_csv('data/toxic_train.tsv', sep='\\t')\n",
    "X_test.to_csv('data/toxic_test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_tokens = X_train.comment.apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrases = gensim.models.phrases.Phrases(simple_tokens)\n",
    "tokenizer = gensim.models.phrases.Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_text = list(tokenizer[simple_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crete',\n",
       " 'jpg',\n",
       " 'hello',\n",
       " 'wikied',\n",
       " 'am',\n",
       " 'wondering_if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'clear',\n",
       " 'up',\n",
       " 'some',\n",
       " 'questions',\n",
       " 'have',\n",
       " 'about',\n",
       " 'crete',\n",
       " 'jpgfor',\n",
       " 'the',\n",
       " 'source',\n",
       " 'of',\n",
       " 'the',\n",
       " 'photo',\n",
       " 'you',\n",
       " 'write',\n",
       " 'from',\n",
       " 'collection',\n",
       " 'of',\n",
       " 'wikieds',\n",
       " 'great',\n",
       " 'uncle',\n",
       " 'probably',\n",
       " 'traded',\n",
       " 'what',\n",
       " 'does',\n",
       " 'this',\n",
       " 'mean',\n",
       " 'exactly',\n",
       " 'does',\n",
       " 'it',\n",
       " 'mean',\n",
       " 'that',\n",
       " 'your',\n",
       " 'great',\n",
       " 'uncle',\n",
       " 'took',\n",
       " 'the',\n",
       " 'photo',\n",
       " 'or',\n",
       " 'that',\n",
       " 'someone_else',\n",
       " 'did',\n",
       " 'and',\n",
       " 'your',\n",
       " 'great',\n",
       " 'uncle',\n",
       " 'traded',\n",
       " 'for',\n",
       " 'it',\n",
       " 'you',\n",
       " 'have',\n",
       " 'also',\n",
       " 'tagged',\n",
       " 'the',\n",
       " 'image',\n",
       " 'with',\n",
       " 'pdself',\n",
       " 'which',\n",
       " 'says',\n",
       " 'the',\n",
       " 'creator',\n",
       " 'of',\n",
       " 'this',\n",
       " 'work',\n",
       " 'but',\n",
       " 'apparently',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'actually',\n",
       " 'the',\n",
       " 'creatoralso',\n",
       " 'in',\n",
       " 'the',\n",
       " 'summary',\n",
       " 'section',\n",
       " 'you',\n",
       " 'say',\n",
       " 'that',\n",
       " 'the',\n",
       " 'image',\n",
       " 'is',\n",
       " 'released_under',\n",
       " 'the',\n",
       " 'gfdl',\n",
       " 'but',\n",
       " 'in',\n",
       " 'the',\n",
       " 'licensing',\n",
       " 'section',\n",
       " 'you',\n",
       " 'state',\n",
       " 'that',\n",
       " 'you',\n",
       " 'have',\n",
       " 'released',\n",
       " 'the',\n",
       " 'image',\n",
       " 'into',\n",
       " 'the',\n",
       " 'public_domain',\n",
       " 'which',\n",
       " 'of',\n",
       " 'these',\n",
       " 'is',\n",
       " 'the',\n",
       " 'case']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_dict = gensim.corpora.dictionary.Dictionary(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rev_id', 'comment', 'toxic'], dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET_CLASSES = ['toxic']\n",
    "targets = X_train[TARGET_CLASSES].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ..., \n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 400)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAHVNJREFUeJzt3Xu0XWV97vHvQ7jLJdzEHAINSIYC\niiFGktZLLSoEPDVg0QHaksFBowLnaLVWsD0FL3RITwXFo9QoKUHFgFwk0nAwXKoyKoEAIReQsgso\niZFYQrhJg8Bz/pjvlsV2752VZL97rb3zfMZYY8/5m+9c8zdn2PvHnOtd7yvbRERE1LRVpxOIiIjR\nL8UmIiKqS7GJiIjqUmwiIqK6FJuIiKguxSYiIqpLsYmIiOpSbCIioroUm4iIqG7rTicw3Pbcc09P\nmDCh02lERIwod9xxx3/a3mtT99/iis2ECRNYvHhxp9OIiBhRJP18c/bPY7SIiKguxSYiIqpLsYmI\niOqqFRtJ20u6TdLdklZI+kyJXyzpQUlLymtSiUvSBZJ6JC2VNLnlvWZKur+8ZrbEXy9pWdnnAkmq\ndT4REbHpanYQWA8cYfspSdsAt0i6rmz7pO0r+rQ/GphYXlOBC4GpknYHzgKmAAbukDTf9mOlzQeB\nRcACYDpwHRER0VWq3dm48VRZ3aa8BpupbQZwSdnvVmCspHHAUcBC22tLgVkITC/bdrF9q5sZ4C4B\njq11PhERsemqfmYjaYykJcAamoKxqGw6pzwqO1/SdiW2D/Bwy+4rS2yw+Mp+4hER0WWqFhvbz9ue\nBIwHDpf0GuBM4NXAG4DdgU/VzAFA0ixJiyUt/vWvf137cBER0cew9EazvQ64GZhue3V5VLYe+Gfg\n8NJsFbBvy27jS2yw+Ph+4v0df7btKban7LXXJn8BNiIiNlG1DgKS9gJ+a3udpB2AdwDnShpne3Xp\nOXYssLzsMh84XdI8mg4Cj5d21wN/L2m30u5I4EzbayU9IWkaTQeBk4CvbCivtU8/y6WLftHWObxv\n6n7tn3BERAyoZm+0ccBcSWNo7qAut32tpJtKIRKwBPhwab8AOAboAX4DnAxQisrngNtLu8/aXluW\nTwUuBnag6YWWnmgREV2oWrGxvRQ4rJ/4EQO0N3DaANvmAHP6iS8GXrN5mUZERG0ZQSAiIqpLsYmI\niOpSbCIioroUm4iIqC7FJiIiqkuxiYiI6lJsIiKiuhSbiIioLsUmIiKqS7GJiIjqUmwiIqK6FJuI\niKguxSYiIqpLsYmIiOpSbCIioroUm4iIqK7mTJ0jXrvTR0OmkI6IGEzubCIioroUm4iIqC7FJiIi\nqkuxiYiI6qoVG0nbS7pN0t2SVkj6TInvL2mRpB5Jl0natsS3K+s9ZfuElvc6s8Tvk3RUS3x6ifVI\nOqPWuURExOapeWezHjjC9uuAScB0SdOAc4HzbR8IPAacUtqfAjxW4ueXdkg6GDgBOASYDnxN0hhJ\nY4CvAkcDBwMnlrYREdFlqhUbN54qq9uUl4EjgCtKfC5wbFmeUdYp298mSSU+z/Z62w8CPcDh5dVj\n+wHbzwLzStuIiOgyVT+zKXcgS4A1wELgP4B1tp8rTVYC+5TlfYCHAcr2x4E9WuN99hkoHhERXaZq\nsbH9vO1JwHiaO5FX1zzeQCTNkrRY0uIn163tRAoREVu0YemNZnsdcDPwh8BYSb0jF4wHVpXlVcC+\nAGX7rsCjrfE++wwU7+/4s21PsT1l57G7D8k5RURE+2r2RttL0tiyvAPwDuBemqJzfGk2E7imLM8v\n65TtN9l2iZ9QeqvtD0wEbgNuByaW3m3b0nQimF/rfCIiYtPVHBttHDC39BrbCrjc9rWS7gHmSfo8\ncBdwUWl/EfAtST3AWprige0Vki4H7gGeA06z/TyApNOB64ExwBzbKyqeT0REbKJqxcb2UuCwfuIP\n0Hx+0zf+X8B7Bnivc4Bz+okvABZsdrIREVFVRhCIiIjqUmwiIqK6FJuIiKguxSYiIqpLsYmIiOpS\nbCIioroUm4iIqC7FJiIiqkuxiYiI6lJsIiKiuhSbiIioLsUmIiKqS7GJiIjqUmwiIqK6FJuIiKgu\nxSYiIqpLsYmIiOpSbCIioroUm4iIqC7FJiIiqkuxiYiI6qoVG0n7SrpZ0j2SVkj6aImfLWmVpCXl\ndUzLPmdK6pF0n6SjWuLTS6xH0hkt8f0lLSrxyyRtW+t8IiJi09W8s3kO+ITtg4FpwGmSDi7bzrc9\nqbwWAJRtJwCHANOBr0kaI2kM8FXgaOBg4MSW9zm3vNeBwGPAKRXPJyIiNlG1YmN7te07y/KTwL3A\nPoPsMgOYZ3u97QeBHuDw8uqx/YDtZ4F5wAxJAo4Arij7zwWOrXM2ERGxOYblMxtJE4DDgEUldLqk\npZLmSNqtxPYBHm7ZbWWJDRTfA1hn+7k+8f6OP0vSYkmLn1y3dgjOKCIiNkb1YiNpJ+BK4GO2nwAu\nBF4JTAJWA1+snYPt2ban2J6y89jdax8uIiL62Lrmm0vahqbQfMf2VQC2H2nZ/g3g2rK6Cti3Zffx\nJcYA8UeBsZK2Lnc3re0jIqKL1OyNJuAi4F7b57XEx7U0Ow5YXpbnAydI2k7S/sBE4DbgdmBi6Xm2\nLU0ngvm2DdwMHF/2nwlcU+t8IiJi09W8s3kj8BfAMklLSuzTNL3JJgEGHgI+BGB7haTLgXtoerKd\nZvt5AEmnA9cDY4A5tleU9/sUME/S54G7aIpbRER0mWrFxvYtgPrZtGCQfc4BzuknvqC//Ww/QNNb\nLSIiulhGEIiIiOpSbCIioroUm4iIqC7FJiIiqkuxiYiI6lJsIiKiuhSbiIioLsUmIiKqS7GJiIjq\nUmwiIqK6FJuIiKiurWIj6bW1E4mIiNGr3Tubr0m6TdKpknatmlFERIw6bRUb228G3k8zidkdki6V\n9I6qmUVExKjR9mc2tu8H/pZmDpk/Bi6Q9DNJ766VXEREjA7tfmZzqKTzgXuBI4A/tX1QWT6/Yn4R\nETEKtDt52leAbwKftv1Mb9D2LyX9bZXMIiJi1Gi32LwTeKZlmuatgO1t/8b2t6plFxERo0K7n9nc\nAOzQsr5jiUVERGxQu8Vme9tP9a6U5R3rpBQREaNNu8XmaUmTe1ckvR54ZpD2ERERv9NusfkY8D1J\nP5F0C3AZcPpgO0jaV9LNku6RtELSR0t8d0kLJd1ffu5W4pJ0gaQeSUv7FLeZpf39kma2xF8vaVnZ\n5wJJ2tgLEBER9bX7pc7bgVcDHwE+DBxk+44N7PYc8AnbBwPTgNMkHQycAdxoeyJwY1kHOBqYWF6z\ngAuhKU7AWcBU4HDgrN4CVdp8sGW/6e2cT0REDK+NGYjzDcChwGTgREknDdbY9mrbd5blJ2m+o7MP\nMAOYW5rNBY4tyzOAS9y4FRgraRxwFLDQ9lrbjwELgell2y62b7Vt4JKW94qIiC7SVtdnSd8CXgks\nAZ4v4d4/8O3sPwE4DFgE7G17ddn0K2DvsrwP8HDLbitLbLD4yn7i/R1/Fs3dEnu+ot8mERFRUbvf\ns5kCHFzuIDaKpJ2AK4GP2X6i9WMV25a00e+5sWzPBmYDHHDQodWPFxERL9XuY7TlwCs29s0lbUNT\naL5j+6oSfqQ8AqP8XFPiq2gG+uw1vsQGi4/vJx4REV2m3TubPYF7JN0GrO8N2n7XQDuUnmEXAffa\nPq9l03xgJvCF8vOalvjpkubRdAZ43PZqSdcDf9/SKeBI4EzbayU9IWkazeO5k2iG1emISxf9YqPa\nv2/qfpUyiYjoPu0Wm7M34b3fCPwFsEzSkhL7NE2RuVzSKcDPgfeWbQuAY4Ae4DfAyQClqHwOuL20\n+6zttWX5VOBimtENriuviIjoMm0VG9s/kvQHwETbN0jaERizgX1uAQb63svb+mlv4LQB3msOMKef\n+GLgNRtIPyIiOqzdKQY+CFwBfL2E9gG+XyupiIgYXdrtIHAazWOxJ+B3E6m9vFZSERExurRbbNbb\nfrZ3RdLWNN+ziYiI2KB2i82PJH0a2EHSO4DvAT+ol1ZERIwm7RabM4BfA8uAD9H0HMsMnRER0ZZ2\ne6O9AHyjvCIiIjZKu2OjPUg/n9HYPmDIM4qIiFFnY8ZG67U98B5g96FPJyIiRqN257N5tOW1yvaX\ngHdWzi0iIkaJdh+jTW5Z3YrmTqfdu6KIiNjCtVswvtiy/BzwEC+OaRYRETGodnuj/UntRCIiYvRq\n9zHaxwfb3mcKgYiIiJfYmN5ob6CZcwbgT4HbgPtrJBUREaNLu8VmPDDZ9pMAks4G/sX2n9dKLCIi\nRo92h6vZG3i2Zf3ZEouIiNigdu9sLgFuk3R1WT8WmFsnpYiIGG3a7Y12jqTrgDeX0Mm276qXVkRE\njCbtPkYD2BF4wvaXgZWS9q+UU0REjDLtTgt9FvAp4MwS2gb4dq2kIiJidGn3zuY44F3A0wC2fwns\nXCupiIgYXdotNs/aNmWaAUkv29AOkuZIWiNpeUvsbEmrJC0pr2Natp0pqUfSfZKOaolPL7EeSWe0\nxPeXtKjEL5O0bZvnEhERw6zdYnO5pK8DYyV9ELiBDU+kdjEwvZ/4+bYnldcCAEkHAycAh5R9viZp\njKQxwFeBo4GDgRNLW4Bzy3sdCDwGnNLmuURExDBrd4qBfwSuAK4EXgX8ne2vbGCfHwNr28xjBjDP\n9nrbDwI9wOHl1WP7AdvPAvOAGZIEHFFygqYb9rFtHisiIobZBrs+l7uLG8pgnAuH4JinSzoJWAx8\nwvZjwD7ArS1tVpYYwMN94lOBPYB1tp/rp31/5zALmAWw5ysGbBYREZVs8M7G9vPAC5J2HYLjXQi8\nEpgErOalUxdUY3u27Sm2p+w8NhOMRkQMt3ZHEHgKWCZpIaVHGoDt/7UxB7P9SO+ypG8A15bVVcC+\nLU3HlxgDxB+l+fxo63J309o+IiK6TLvF5qry2iySxtleXVaPA3p7qs0HLpV0HvDfgIk0o0oLmFi+\nQLqKphPB+2xb0s3A8TSf48wErtnc/CIioo5Bi42k/Wz/wvZGj4Mm6bvAW4E9Ja0EzgLeKmkSTRfq\nh4APAdheIely4B6amUBPK4/vkHQ6cD0wBphje0U5xKeAeZI+D9wFXLSxOUZExPBQ8/WZATZKd9qe\nXJavtP1nw5ZZJQccdKg/f/G1G27YRd43db9OpxARWzhJd9iesqn7b6iDgFqWD9jUg0RExJZtQ8XG\nAyxHRES0bUMdBF4n6QmaO5wdyjJl3bZ3qZpdRESMCoMWG9tjhiuRiIgYvTZmPpuIiIhNkmITERHV\npdhERER1KTYREVFdik1ERFSXYhMREdWl2ERERHUpNhERUV2KTUREVJdiExER1aXYREREdSk2ERFR\nXYpNRERUl2ITERHVpdhERER1KTYREVFdtWIjaY6kNZKWt8R2l7RQ0v3l524lLkkXSOqRtFTS5JZ9\nZpb290ua2RJ/vaRlZZ8LJKnWuURExOapeWdzMTC9T+wM4EbbE4EbyzrA0cDE8poFXAhNcQLOAqYC\nhwNn9Rao0uaDLfv1PVZERHSJasXG9o+BtX3CM4C5ZXkucGxL/BI3bgXGShoHHAUstL3W9mPAQmB6\n2baL7VttG7ik5b0iIqLLDPdnNnvbXl2WfwXsXZb3AR5uabeyxAaLr+wnHhERXahjHQTKHYmH41iS\nZklaLGnxk+v63mxFRERtw11sHimPwCg/15T4KmDflnbjS2yw+Ph+4v2yPdv2FNtTdh67+2afRERE\nbJzhLjbzgd4eZTOBa1riJ5VeadOAx8vjtuuBIyXtVjoGHAlcX7Y9IWla6YV2Ust7RUREl9m61htL\n+i7wVmBPSStpepV9Abhc0inAz4H3luYLgGOAHuA3wMkAttdK+hxwe2n3Wdu9z8FOpenxtgNwXXlF\nREQXqlZsbJ84wKa39dPWwGkDvM8cYE4/8cXAazYnx4iIGB7Vik0MnUsX/aLttu+bul/FTCIiNk2G\nq4mIiOpSbCIioroUm4iIqC7FJiIiqkuxiYiI6lJsIiKiuhSbiIioLsUmIiKqS7GJiIjqUmwiIqK6\nFJuIiKguxSYiIqrLQJyjzMYM2gkZuDMihkfubCIioroUm4iIqC7FJiIiqkuxiYiI6lJsIiKiuhSb\niIioLsUmIiKq60ixkfSQpGWSlkhaXGK7S1oo6f7yc7cSl6QLJPVIWippcsv7zCzt75c0sxPnEhER\nG9bJO5s/sT3J9pSyfgZwo+2JwI1lHeBoYGJ5zQIuhKY4AWcBU4HDgbN6C1RERHSXbnqMNgOYW5bn\nAse2xC9x41ZgrKRxwFHAQttrbT8GLASmD3fSERGxYZ0qNgZ+KOkOSbNKbG/bq8vyr4C9y/I+wMMt\n+64ssYHiERHRZTo1NtqbbK+S9HJgoaSftW60bUkeqoOVgjYLYM9XpB5FRAy3jhQb26vKzzWSrqb5\nzOURSeNsry6PydaU5quAfVt2H19iq4C39on/6wDHmw3MBjjgoEOHrIiNBhszcGcG7YyITTXsj9Ek\nvUzSzr3LwJHAcmA+0NujbCZwTVmeD5xUeqVNAx4vj9uuB46UtFvpGHBkiUVERJfpxJ3N3sDVknqP\nf6nt/yfpduBySacAPwfeW9ovAI4BeoDfACcD2F4r6XPA7aXdZ22vHb7TiIiIdg17sbH9APC6fuKP\nAm/rJ27gtAHeaw4wZ6hzjIiIodVNXZ8jImKUykyd0bZ0JoiITZU7m4iIqC7FJiIiqkuxiYiI6lJs\nIiKiuhSbiIioLsUmIiKqS9fnqGJjuklDukpHjHa5s4mIiOpyZxNdIV8YjRjdcmcTERHVpdhERER1\neYwWI04euUWMPCk2MaqlV1xEd8hjtIiIqC7FJiIiqstjtIgW+Twooo7c2URERHW5s4nYRLkLimhf\nik3EMNjYXnEbI4UsRoIRX2wkTQe+DIwBvmn7Cx1OKWJY5Q4rRoIRXWwkjQG+CrwDWAncLmm+7Xs6\nm1lEd8odVnTKiC42wOFAj+0HACTNA2YAKTYRw6xmIatlYwtk7iI33UgvNvsAD7esrwSmdiiXiBhh\nahbIkVh8axrpxaYtkmYBs8rq+vdP+4PlncynTXsC/9npJDZgJOQIyXOoJc+hNVLyfNXm7DzSi80q\nYN+W9fEl9hK2ZwOzASQttj1leNLbdCMhz5GQIyTPoZY8h9ZIynNz9h/pX+q8HZgoaX9J2wInAPM7\nnFNERPQxou9sbD8n6XTgepquz3Nsr+hwWhER0ceILjYAthcACzZil9m1chliIyHPkZAjJM+hljyH\n1haRp2wPVSIRERH9Gumf2URExAiwxRQbSdMl3SepR9IZnc6nlaSHJC2TtKS3x4ek3SUtlHR/+blb\nB/KaI2mNpOUtsX7zUuOCcn2XSprc4TzPlrSqXNMlko5p2XZmyfM+SUcNU477SrpZ0j2SVkj6aIl3\n1fUcJM9uu57bS7pN0t0lz8+U+P6SFpV8Lisdh5C0XVnvKdsndDjPiyU92HI9J5V4x36PyvHHSLpL\n0rVlfeiup+1R/6LpPPAfwAHAtsDdwMGdzqslv4eAPfvE/gE4oyyfAZzbgbzeAkwGlm8oL+AY4DpA\nwDRgUYfzPBv4q37aHlz+/bcD9i//XYwZhhzHAZPL8s7Av5dcuup6DpJnt11PATuV5W2AReU6XQ6c\nUOL/BHykLJ8K/FNZPgG4bJiu50B5Xgwc30/7jv0eleN/HLgUuLasD9n13FLubH43rI3tZ4HeYW26\n2QxgblmeCxw73AnY/jGwtk94oLxmAJe4cSswVtK4DuY5kBnAPNvrbT8I9ND891GV7dW27yzLTwL3\n0oyA0VXXc5A8B9Kp62nbT5XVbcrLwBHAFSXe93r2XucrgLdJUgfzHEjHfo8kjQfeCXyzrIshvJ5b\nSrHpb1ibwX6BhpuBH0q6Q81oBwB7215dln8F7N2Z1H7PQHl14zU+vTyKmNPyGLLjeZZHDofR/F9u\n117PPnlCl13P8shnCbAGWEhzV7XO9nP95PK7PMv2x4E9OpGn7d7reU65nudL2q5vnsVw/rt/Cfhr\n4IWyvgdDeD23lGLT7d5kezJwNHCapLe0bnRzr9p13Qa7Na/iQuCVwCRgNfDFzqbTkLQTcCXwMdtP\ntG7rpuvZT55ddz1tP297Es3IIYcDr+5wSv3qm6ek1wBn0uT7BmB34FMdTBFJ/x1YY/uOWsfYUopN\nW8PadIrtVeXnGuBqml+cR3pvn8vPNZ3L8CUGyqurrrHtR8ov+QvAN3jx0U7H8pS0Dc0f8O/YvqqE\nu+569pdnN17PXrbXATcDf0jz2Kn3+4Otufwuz7J9V+DRDuU5vTyutO31wD/T+ev5RuBdkh6i+Zjh\nCJp5wobsem4pxaZrh7WR9DJJO/cuA0cCy2nym1mazQSu6UyGv2egvOYDJ5XeNNOAx1seDw27Ps+5\nj6O5ptDkeULpTbM/MBG4bRjyEXARcK/t81o2ddX1HCjPLryee0kaW5Z3oJnT6l6aP+bHl2Z9r2fv\ndT4euKncSXYiz5+1/A+GaD4Hab2ew/7vbvtM2+NtT6D5+3iT7fczlNezdu+GbnnR9PL4d5rnun/T\n6Xxa8jqApjfP3cCK3txonn/eCNwP3ADs3oHcvkvzyOS3NM9rTxkoL5reM18t13cZMKXDeX6r5LG0\n/GKMa2n/NyXP+4CjhynHN9E8IlsKLCmvY7rteg6SZ7ddz0OBu0o+y4G/K/EDaIpdD/A9YLsS376s\n95TtB3Q4z5vK9VwOfJsXe6x17PeoJee38mJvtCG7nhlBICIiqttSHqNFREQHpdhERER1KTYREVFd\nik1ERFSXYhMREdWl2MSII2mPltFyf6WXjka8bT/tDyzDhQxHbsdJ+uRwHKtbSXq3pK78Nn90zoif\nqTO2PLYfpRk2BUlnA0/Z/seOJlXYvrrTOXSBd9OMr/WzTicS3SN3NjGqSPprScvL63/2s/3AMl/H\nZElbSzpPzXwjSyV9oLR5u6QbJV2lZo6WS1r2/z9q5npZKuncft7/A5K+VJa/LenLkv5N0gOSjhsg\n5x+UQVhX9ObQT5upkn6qZl6URZJ2lLSDpLlq5kK6s3dMvZLDVZJukPRzSR+R9Mly3v/W8o32W8r5\nLy7nNEXS1Wrm1jm75dgzyzVaIulrkrYq126dpC+UnH4q6eWS3kzzJdDzS/sJbf/jxaiWO5sYNSRN\nBd5PM7jh1sBtkv4VeKZsP4hmro6TbC+TdCrN4IOHqxl191ZJPyxvNxk4BHikxKcBD9L8IT3Etnv/\naG/Ay2nGnXotzdwg/d35zLS9VtKOwGJJV9p+rOW8tqcZr+rPbN8paVdgPfBXwHrbr5V0CLBA0sSy\n2yHlHHaiGZ3g47YPk/QV4M+B/1vaPWN7iqRPAN8HXk8zgu8DpWiOpxme5o9sPydpNs1wJpfTjIf1\nI9tnSDoP+B+2vyBpAXCF7e+3cX1iC5E7mxhN3gRcafsZN3OxfB94c9m2N80f+hNtLyuxI4GTy+c5\ni4CxNGN7Adxq+5e2n6cZsmUCzZw5LwDfKHcpT7eR0/fdWMrAQ8X/paS7gZ/S/HF/ZZ/tBwG/8Ivz\nzDxe8noTzVAn2F4B/BI4sOxzk+2nbT8CPAX8oMSXlXPpNb8lvszNgJv/RTOh33jg7TTFe3G5Tn/c\nkt8ztq8ry3f0ed+Il8idTWwp1tH8Mf4jXvwsQcCptm9sbSjp7TR3Dr2eB7a2/VtJU2gGU3wP8BGa\ngjWY1vf5vcmlyrHeAkyz/YykW2jGndpcrcd9oWX9BV76e7++nzat7QTMsf2/++S9NfBsS+h58vck\nBpE7mxhNfgIcVz7L2IlmNsGflG3ry/oHJL23xK4HTi1/OJH0KjUj8/ZLzejcu9i+FvhLmonFNteu\nwNpSaA6huYvo6x5gP5X56CXtImlMObf3l9hBNFM69wxBTq1uAN4rac9ynD0k7beBfZ6kmVI64nfy\nfyIxati+TdJ3aaaUALiwfDZzYNn+lJpJohZKehr4OrAfsETNjLZrGHy68F2Bq8rnO1vRzNe+uf4F\nmCXpHppRkxf1bWB7vaQTgQvL5zfP0Mw38hXg65KW0Yx4fZLtZzWEsx2X6/cZ4AZJW5XjfJjmLnEg\n3y15fQI41vZDQ5ZQjFgZ9TkiIqrLY7SIiKguxSYiIqpLsYmIiOpSbCIioroUm4iIqC7FJiIiqkux\niYiI6lJsIiKiuv8PkhQko2YlzTQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17187d358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot([len(doc) for doc in tokenized_text], bins=100, kde=False, label='Number of tokens per comment.')\n",
    "plt.xlabel(\"Tokens in a comment\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim((0, 400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training word2vec on comment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = gensim.models.word2vec.Word2Vec(tokenized_text, window=5, size=100, min_count=2, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reference', 0.8324511647224426),\n",
       " ('source', 0.8086929321289062),\n",
       " ('ref', 0.7720947265625),\n",
       " ('references', 0.7694875001907349),\n",
       " ('citations', 0.7552413940429688),\n",
       " ('reliable_source', 0.7348667979240417),\n",
       " ('secondary_source', 0.7305512428283691),\n",
       " ('footnote', 0.7250741720199585),\n",
       " ('verification', 0.7163118124008179),\n",
       " ('sources', 0.7059152722358704)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar('citation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dumb', 0.844036340713501),\n",
       " ('pathetic', 0.8346757292747498),\n",
       " ('crazy', 0.8233659863471985),\n",
       " ('retarded', 0.7821276187896729),\n",
       " ('funny', 0.7751038074493408),\n",
       " ('sick', 0.7745219469070435),\n",
       " ('disgusting', 0.7631621360778809),\n",
       " ('ugly', 0.761038064956665),\n",
       " ('lazy', 0.7598941326141357),\n",
       " ('silly', 0.7505162954330444)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar('stupid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec-based model\n",
    "\n",
    "Aggregate word embeddings per comment (~ tf-idf weighted averaging), and use that as an input feature in a neural net with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.zeros((len(tokenized_text), word2vec.vector_size))\n",
    "for i, tokens in enumerate(tokenized_text):\n",
    "    tokens = [t for t in tokens if t in word2vec.wv.vocab]\n",
    "    if tokens:\n",
    "        features[i, :] = np.mean([word2vec.wv[t] / word2vec.wv.vocab[t].count for t in tokens], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "#model.add(Dense(256, activation='relu', input_shape=(word2vec.vector_size,)))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(len(TARGET_CLASSES), activation='sigmoid'))\n",
    "#model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(features, targets, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential models\n",
    "\n",
    "Simply averaging embeddings across all terms in a comment loses interactions that can occur between words, and the importance of their position. Because of this, we will now experiment with position-aware models: LSTM and CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: shifting indices by 1 as index 0 will be used for padding.\n",
    "docs = [[idx + 1 for idx in corpus_dict.doc2idx(doc)]  for doc in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 50\n",
    "padded_docs = keras.preprocessing.sequence.pad_sequences(docs, maxlen=MAX_SEQ_LEN, truncating='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241649"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idx = max(c for d in docs for c in d)\n",
    "max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = np.array([np.random.normal(size=word2vec.vector_size)]+ # for the '0' padding word\n",
    "                      [word2vec.wv[corpus_dict[idx]]\n",
    "                      if corpus_dict[idx] in word2vec.wv.vocab\n",
    "                      else np.random.normal(size=word2vec.vector_size)\n",
    "                      for idx in range(max_idx)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import Convolution1D, MaxPool1D, Flatten, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_idx + 1, word2vec.vector_size, input_length=MAX_SEQ_LEN))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution1D(52, 5, padding='same',\n",
    "                        kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "model.add(MaxPool1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution1D(128, 3, padding='same',\n",
    "                        kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "model.add(MaxPool1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(TARGET_CLASSES), activation='sigmoid',\n",
    "                kernel_regularizer=keras.regularizers.l2(0.02)))\n",
    "model.compile(Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 129345 samples, validate on 14372 samples\n",
      "Epoch 1/20\n",
      "129345/129345 [==============================] - 136s 1ms/step - loss: 0.7663 - acc: 0.8653 - val_loss: 0.4417 - val_acc: 0.8569\n",
      "Epoch 2/20\n",
      "129345/129345 [==============================] - 137s 1ms/step - loss: 0.3009 - acc: 0.8997 - val_loss: 0.3915 - val_acc: 0.8655\n",
      "Epoch 3/20\n",
      "129345/129345 [==============================] - 136s 1ms/step - loss: 0.2385 - acc: 0.9189 - val_loss: 0.3708 - val_acc: 0.8890\n",
      "Epoch 4/20\n",
      "129345/129345 [==============================] - 126s 976us/step - loss: 0.1983 - acc: 0.9358 - val_loss: 0.3755 - val_acc: 0.8902\n",
      "Epoch 5/20\n",
      "129345/129345 [==============================] - 135s 1ms/step - loss: 0.1720 - acc: 0.9463 - val_loss: 0.4404 - val_acc: 0.8844\n",
      "Epoch 6/20\n",
      "129345/129345 [==============================] - 136s 1ms/step - loss: 0.1522 - acc: 0.9552 - val_loss: 0.4782 - val_acc: 0.8651\n",
      "Epoch 7/20\n",
      "129345/129345 [==============================] - 134s 1ms/step - loss: 0.1351 - acc: 0.9625 - val_loss: 0.4832 - val_acc: 0.8796\n",
      "Epoch 8/20\n",
      "129345/129345 [==============================] - 139s 1ms/step - loss: 0.1233 - acc: 0.9673 - val_loss: 0.5115 - val_acc: 0.8736\n",
      "Epoch 9/20\n",
      "129345/129345 [==============================] - 141s 1ms/step - loss: 0.1134 - acc: 0.9710 - val_loss: 0.5303 - val_acc: 0.8746\n",
      "Epoch 10/20\n",
      "129345/129345 [==============================] - 143s 1ms/step - loss: 0.1073 - acc: 0.9732 - val_loss: 0.5443 - val_acc: 0.8720\n",
      "Epoch 11/20\n",
      "129345/129345 [==============================] - 142s 1ms/step - loss: 0.1004 - acc: 0.9756 - val_loss: 0.5832 - val_acc: 0.8724\n",
      "Epoch 12/20\n",
      "129345/129345 [==============================] - 140s 1ms/step - loss: 0.0961 - acc: 0.9775 - val_loss: 0.5855 - val_acc: 0.8553\n",
      "Epoch 13/20\n",
      "129345/129345 [==============================] - 139s 1ms/step - loss: 0.0921 - acc: 0.9787 - val_loss: 0.6493 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "129345/129345 [==============================] - 142s 1ms/step - loss: 0.0879 - acc: 0.9803 - val_loss: 0.6509 - val_acc: 0.8723\n",
      "Epoch 15/20\n",
      "129345/129345 [==============================] - 141s 1ms/step - loss: 0.0843 - acc: 0.9816 - val_loss: 0.6943 - val_acc: 0.8777\n",
      "Epoch 16/20\n",
      "129345/129345 [==============================] - 142s 1ms/step - loss: 0.0815 - acc: 0.9824 - val_loss: 0.6305 - val_acc: 0.8639\n",
      "Epoch 17/20\n",
      "129345/129345 [==============================] - 138s 1ms/step - loss: 0.0791 - acc: 0.9829 - val_loss: 0.6559 - val_acc: 0.8720\n",
      "Epoch 18/20\n",
      "129345/129345 [==============================] - 139s 1ms/step - loss: 0.0765 - acc: 0.9843 - val_loss: 0.6627 - val_acc: 0.8708\n",
      "Epoch 19/20\n",
      "129345/129345 [==============================] - 139s 1ms/step - loss: 0.0743 - acc: 0.9845 - val_loss: 0.5983 - val_acc: 0.8736\n",
      "Epoch 20/20\n",
      "129345/129345 [==============================] - 138s 1ms/step - loss: 0.0734 - acc: 0.9848 - val_loss: 0.6792 - val_acc: 0.8624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15107fd68>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_docs, targets, batch_size=512, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights('models/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comment_to_sequential_input(comment):\n",
    "    tokens = tokenizer[gensim.utils.simple_preprocess(comment)]\n",
    "    t_ids = [corpus_dict.token2id[t] + 1 for t in tokens if t in word2vec.wv.vocab and t in corpus_dict.token2id]\n",
    "    return keras.preprocessing.sequence.pad_sequences([t_ids], maxlen=MAX_SEQ_LEN)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(comment):\n",
    "    test_input = [comment_to_sequential_input(comment).reshape(1, -1)]\n",
    "    for target_class, score in zip(TARGET_CLASSES, model.predict(test_input)[0]):\n",
    "        print(\"{}: {:.2f}%\".format(target_class, score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 56.00%\n"
     ]
    }
   ],
   "source": [
    "comment = \"Why are we having all these people from shithole countries come here?\"\n",
    "predict(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 99.10%\n"
     ]
    }
   ],
   "source": [
    "comment = 'You suck, loser!'\n",
    "predict(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 2.35%\n"
     ]
    }
   ],
   "source": [
    "comment = \"Now is the time for all good persons to come to the aid of their country\"\n",
    "predict(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = np.array([comment_to_sequential_input(doc) for doc in X_test.comment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = X_test.as_matrix(columns=['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86655394827478238"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      toxic       0.90      0.94      0.92     13612\n",
      "\n",
      "avg / total       0.85      0.87      0.86     15969\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbatz/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 2, does not match size of target_names, 1\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "target_names = ['toxic']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
