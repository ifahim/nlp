{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction.\n",
    "\n",
    "These are some (modest) attempts at participating in Jigsaw's toxic comments classification problem. For now, I am not using any external data, only the training data given (which is limiting as it's a tiny dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gensim\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import re\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boardgame-comments.csv\r\n",
      "boardgame-frequent-user-comments.csv\r\n",
      "glove.6B.50d.txt\r\n",
      "glove.6B.50d.txt.zip\r\n",
      "sample_submission.csv\r\n",
      "sample_submission.csv.zip\r\n",
      "test.csv\r\n",
      "test.csv.zip\r\n",
      "toxicity_annotated_comments.tsv\r\n",
      "toxicity_annotated_comments_unanimous.tsv\r\n",
      "toxicity_annotations.tsv\r\n",
      "toxicity_annotations_unanimous.tsv\r\n",
      "toxicity_worker_demographics.tsv\r\n",
      "train.csv\r\n",
      "train.csv.zip\r\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/toxicity_annotated_comments.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...  2002   \n",
       "1   4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  \n",
       "0       True  article  random  train  \n",
       "1       True     user  random  train  \n",
       "2      False  article  random   test  \n",
       "3       True  article  random  train  \n",
       "4       True  article  random   test  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159686"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = pd.read_csv('data/toxicity_annotations.tsv',  sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3989</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>1508</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>4020</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id  worker_id  toxicity  toxicity_score\n",
       "0  2232.0        723         0             0.0\n",
       "1  2232.0       4000         0             0.0\n",
       "2  2232.0       3989         0             1.0\n",
       "3  2232.0       3341         0             0.0\n",
       "4  2232.0       1574         0             1.0\n",
       "5  2232.0       1508         0             1.0\n",
       "6  2232.0        772         0             1.0\n",
       "7  2232.0        680         0             0.0\n",
       "8  2232.0        405         0             1.0\n",
       "9  2232.0       4020         1            -1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores.drop_duplicates(subset='rev_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159686"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.merge(scores, on='rev_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159686"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>2596</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>1642</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35367.0</td>\n",
       "      <td>`:In an interpreted language your source code ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>1408</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37330.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37346.0</td>\n",
       "      <td>`If they are ``indisputable`` then why does th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37675.0</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44377.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe co...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>1927</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...  2002   \n",
       "1   4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "5  35367.0  `:In an interpreted language your source code ...  2002   \n",
       "6  37330.0  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...  2002   \n",
       "7  37346.0  `If they are ``indisputable`` then why does th...  2002   \n",
       "8  37675.0  `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002   \n",
       "9  44377.0  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe co...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  worker_id  toxicity  toxicity_score  \n",
       "0       True  article  random  train        723         0             0.0  \n",
       "1       True     user  random  train        500         0             0.0  \n",
       "2      False  article  random   test       2596         0             1.0  \n",
       "3       True  article  random  train       1642         0             1.0  \n",
       "4       True  article  random   test        202         0             1.0  \n",
       "5       True  article  random    dev       1408         0             1.0  \n",
       "6       True  article  random  train        691         0             0.0  \n",
       "7       True  article  random  train       1108         0             0.0  \n",
       "8      False  article  random    dev        403         0             1.0  \n",
       "9       True  article  random  train       1927         0             2.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['year', 'logged_in', 'split', 'ns', 'sample'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2596</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>1642</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35367.0</td>\n",
       "      <td>`:In an interpreted language your source code ...</td>\n",
       "      <td>1408</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37330.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...</td>\n",
       "      <td>691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37346.0</td>\n",
       "      <td>`If they are ``indisputable`` then why does th...</td>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37675.0</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44377.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe co...</td>\n",
       "      <td>1927</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  worker_id  \\\n",
       "0   2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...        723   \n",
       "1   4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...        500   \n",
       "2   8953.0                          Elected or Electoral? JHK       2596   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...       1642   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...        202   \n",
       "5  35367.0  `:In an interpreted language your source code ...       1408   \n",
       "6  37330.0  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...        691   \n",
       "7  37346.0  `If they are ``indisputable`` then why does th...       1108   \n",
       "8  37675.0  `-NEWLINE_TOKENThis is not ``creative``.  Thos...        403   \n",
       "9  44377.0  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe co...       1927   \n",
       "\n",
       "   toxicity  toxicity_score  \n",
       "0         0             0.0  \n",
       "1         0             0.0  \n",
       "2         0             1.0  \n",
       "3         0             1.0  \n",
       "4         0             1.0  \n",
       "5         0             1.0  \n",
       "6         0             0.0  \n",
       "7         0             0.0  \n",
       "8         0             1.0  \n",
       "9         0             2.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['comment'] = df['comment'].apply(lambda x: re.sub('NEWLINE_TOKEN', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['toxic'] = df['toxicity_score'].apply(lambda x: int(x < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['toxicity', 'toxicity_score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(['toxic'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43160</th>\n",
       "      <td>138798055.0</td>\n",
       "      <td>`==Ck lostsword's RfA - Thanks=={| align=``cen...</td>\n",
       "      <td>3208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124302</th>\n",
       "      <td>485585361.0</td>\n",
       "      <td>== THIS USER IS A PLANT FROM BRUCE PERENS AND ...</td>\n",
       "      <td>1236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124227</th>\n",
       "      <td>485198090.0</td>\n",
       "      <td>this Baboon43 is from Scarborough, Toronto, C...</td>\n",
       "      <td>3869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41554</th>\n",
       "      <td>132533129.0</td>\n",
       "      <td>I really do not see how i am acting immature, ...</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124217</th>\n",
       "      <td>485118928.0</td>\n",
       "      <td>Hello BeCritical,Well, I have to say that aft...</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124215</th>\n",
       "      <td>485070371.0</td>\n",
       "      <td>== fucking nutcase ==you're a fucking nutcase</td>\n",
       "      <td>1513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124213</th>\n",
       "      <td>485069083.0</td>\n",
       "      <td>== nutcase ==you're a sick bloody nutcase</td>\n",
       "      <td>2939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124212</th>\n",
       "      <td>485068088.0</td>\n",
       "      <td>== NUTCASE ==YOU'RE A SICK BLOODY NUTCASE</td>\n",
       "      <td>2334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124209</th>\n",
       "      <td>485055520.0</td>\n",
       "      <td>Oh fuck, not Samuel Johnson. Do you have any i...</td>\n",
       "      <td>3340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41573</th>\n",
       "      <td>132583618.0</td>\n",
       "      <td>== Chinese American Food Society ==I received ...</td>\n",
       "      <td>1937</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rev_id                                            comment  \\\n",
       "43160   138798055.0  `==Ck lostsword's RfA - Thanks=={| align=``cen...   \n",
       "124302  485585361.0  == THIS USER IS A PLANT FROM BRUCE PERENS AND ...   \n",
       "124227  485198090.0   this Baboon43 is from Scarborough, Toronto, C...   \n",
       "41554   132533129.0  I really do not see how i am acting immature, ...   \n",
       "124217  485118928.0   Hello BeCritical,Well, I have to say that aft...   \n",
       "124215  485070371.0      == fucking nutcase ==you're a fucking nutcase   \n",
       "124213  485069083.0          == nutcase ==you're a sick bloody nutcase   \n",
       "124212  485068088.0          == NUTCASE ==YOU'RE A SICK BLOODY NUTCASE   \n",
       "124209  485055520.0  Oh fuck, not Samuel Johnson. Do you have any i...   \n",
       "41573   132583618.0  == Chinese American Food Society ==I received ...   \n",
       "\n",
       "        worker_id  toxic  \n",
       "43160        3208      1  \n",
       "124302       1236      1  \n",
       "124227       3869      1  \n",
       "41554         144      1  \n",
       "124217         24      1  \n",
       "124215       1513      1  \n",
       "124213       2939      1  \n",
       "124212       2334      1  \n",
       "124209       3340      1  \n",
       "41573        1937      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_tokens = df.comment.apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrases = gensim.models.phrases.Phrases(simple_tokens)\n",
    "tokenizer = gensim.models.phrases.Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_text = list(tokenizer[simple_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ck',\n",
       " 'lostsword',\n",
       " 'rfa',\n",
       " 'thanks',\n",
       " 'align_center',\n",
       " 'width_style',\n",
       " 'border',\n",
       " 'ff',\n",
       " 'solid',\n",
       " 'px_moz',\n",
       " 'border_radius',\n",
       " 'px',\n",
       " 'background',\n",
       " 'ebebeb',\n",
       " 'text_align',\n",
       " 'left',\n",
       " 'color_ff',\n",
       " 'padding_px',\n",
       " 'rowspan',\n",
       " 'thanks',\n",
       " 'very_much',\n",
       " 'for',\n",
       " 'your',\n",
       " 'support',\n",
       " 'in',\n",
       " 'my',\n",
       " 'recent_rfa',\n",
       " 'which',\n",
       " 'passed',\n",
       " 'successfully',\n",
       " 'at',\n",
       " 'making',\n",
       " 'me',\n",
       " 'wikipedia',\n",
       " 'th',\n",
       " 'administrator',\n",
       " 'your',\n",
       " 'comments',\n",
       " 'were',\n",
       " 'much_appreciated',\n",
       " 'and',\n",
       " 'will',\n",
       " 'endeavour',\n",
       " 'to',\n",
       " 'fulfil',\n",
       " 'your',\n",
       " 'expectations',\n",
       " 'as',\n",
       " 'an_admin']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_dict = gensim.corpora.dictionary.Dictionary(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rev_id', 'comment', 'worker_id', 'toxic'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET_CLASSES = ['toxic']\n",
    "targets = df[TARGET_CLASSES].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ..., \n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 400)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAWosVd+7L1IbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18744f9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot([len(doc) for doc in tokenized_text], bins=100, kde=False, label='Number of tokens per comment.')\n",
    "plt.xlabel(\"Tokens in a comment\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim((0, 400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training word2vec on comment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = gensim.models.word2vec.Word2Vec(tokenized_text, window=5, size=100, min_count=2, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reference', 0.8477044105529785),\n",
       " ('source', 0.8028237819671631),\n",
       " ('citations', 0.7823623418807983),\n",
       " ('references', 0.7731161117553711),\n",
       " ('footnote', 0.7572417259216309),\n",
       " ('ref', 0.7561527490615845),\n",
       " ('verification', 0.7535486221313477),\n",
       " ('reliable_source', 0.7340558767318726),\n",
       " ('secondary_source', 0.7105909585952759),\n",
       " ('sources', 0.7009351253509521)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar('citation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dumb', 0.8123797178268433),\n",
       " ('crazy', 0.7846869230270386),\n",
       " ('pathetic', 0.7510919570922852),\n",
       " ('funny', 0.7441648840904236),\n",
       " ('silly', 0.7424641847610474),\n",
       " ('retarded', 0.7356431484222412),\n",
       " ('lazy', 0.7324571013450623),\n",
       " ('useless', 0.7085483074188232),\n",
       " ('worthless', 0.6991524696350098),\n",
       " ('annoying', 0.6897914409637451)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar('stupid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec-based model\n",
    "\n",
    "Aggregate word embeddings per comment (~ tf-idf weighted averaging), and use that as an input feature in a neural net with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.zeros((len(tokenized_text), word2vec.vector_size))\n",
    "for i, tokens in enumerate(tokenized_text):\n",
    "    tokens = [t for t in tokens if t in word2vec.wv.vocab]\n",
    "    if tokens:\n",
    "        features[i, :] = np.mean([word2vec.wv[t] / word2vec.wv.vocab[t].count for t in tokens], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159686, 100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159686, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TARGET_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(word2vec.vector_size,)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(TARGET_CLASSES), activation='sigmoid'))\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143717 samples, validate on 15969 samples\n",
      "Epoch 1/10\n",
      "143717/143717 [==============================] - 6s 45us/step - loss: 0.3677 - acc: 0.8547 - val_loss: 0.1645 - val_acc: 0.9698\n",
      "Epoch 2/10\n",
      "143717/143717 [==============================] - 6s 41us/step - loss: 0.3485 - acc: 0.8611 - val_loss: 0.1058 - val_acc: 0.9852\n",
      "Epoch 3/10\n",
      "143717/143717 [==============================] - 6s 43us/step - loss: 0.3446 - acc: 0.8631 - val_loss: 0.1457 - val_acc: 0.9731\n",
      "Epoch 4/10\n",
      "143717/143717 [==============================] - 7s 46us/step - loss: 0.3410 - acc: 0.8649 - val_loss: 0.1309 - val_acc: 0.9820\n",
      "Epoch 5/10\n",
      "143717/143717 [==============================] - 6s 45us/step - loss: 0.3381 - acc: 0.8661 - val_loss: 0.0931 - val_acc: 0.9875\n",
      "Epoch 6/10\n",
      "143717/143717 [==============================] - 6s 43us/step - loss: 0.3365 - acc: 0.8672 - val_loss: 0.0946 - val_acc: 0.9867\n",
      "Epoch 7/10\n",
      "143717/143717 [==============================] - 6s 43us/step - loss: 0.3355 - acc: 0.8678 - val_loss: 0.1052 - val_acc: 0.9803\n",
      "Epoch 8/10\n",
      "143717/143717 [==============================] - 8s 54us/step - loss: 0.3342 - acc: 0.8690 - val_loss: 0.1751 - val_acc: 0.9710\n",
      "Epoch 9/10\n",
      "143717/143717 [==============================] - 7s 47us/step - loss: 0.3333 - acc: 0.8688 - val_loss: 0.1190 - val_acc: 0.9766\n",
      "Epoch 10/10\n",
      "143717/143717 [==============================] - 6s 43us/step - loss: 0.3327 - acc: 0.8695 - val_loss: 0.1380 - val_acc: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1587a6940>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features, targets, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential models\n",
    "\n",
    "Simply averaging embeddings across all terms in a comment loses interactions that can occur between words, and the importance of their position. Because of this, we will now experiment with position-aware models: LSTM and CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: shifting indices by 1 as index 0 will be used for padding.\n",
    "docs = [[idx + 1 for idx in corpus_dict.doc2idx(doc)]  for doc in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 50\n",
    "padded_docs = keras.preprocessing.sequence.pad_sequences(docs, maxlen=MAX_SEQ_LEN, truncating='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191587"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idx = max(c for d in docs for c in d)\n",
    "max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = np.array([np.random.normal(size=word2vec.vector_size)]+ # for the '0' padding word\n",
    "                      [word2vec.wv[corpus_dict[idx]]\n",
    "                      if corpus_dict[idx] in word2vec.wv.vocab\n",
    "                      else np.random.normal(size=word2vec.vector_size)\n",
    "                      for idx in range(max_idx)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import Convolution1D, MaxPool1D, Flatten, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_idx + 1, word2vec.vector_size, input_length=MAX_SEQ_LEN))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution1D(52, 5, padding='same',\n",
    "                        kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "model.add(MaxPool1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution1D(128, 3, padding='same',\n",
    "                        kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "model.add(MaxPool1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(TARGET_CLASSES), activation='sigmoid',\n",
    "                kernel_regularizer=keras.regularizers.l2(0.02)))\n",
    "model.compile(Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143717 samples, validate on 15969 samples\n",
      "Epoch 1/20\n",
      "143717/143717 [==============================] - 126s 874us/step - loss: 0.6820 - acc: 0.8612 - val_loss: 0.1401 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "143717/143717 [==============================] - 126s 877us/step - loss: 0.3031 - acc: 0.8925 - val_loss: 0.0654 - val_acc: 0.9988\n",
      "Epoch 3/20\n",
      "143717/143717 [==============================] - 126s 876us/step - loss: 0.2572 - acc: 0.9090 - val_loss: 0.1257 - val_acc: 0.9811\n",
      "Epoch 4/20\n",
      "143717/143717 [==============================] - 126s 878us/step - loss: 0.2265 - acc: 0.9219 - val_loss: 0.1161 - val_acc: 0.9733\n",
      "Epoch 5/20\n",
      "143717/143717 [==============================] - 126s 879us/step - loss: 0.2037 - acc: 0.9321 - val_loss: 0.1531 - val_acc: 0.9625\n",
      "Epoch 6/20\n",
      "143717/143717 [==============================] - 127s 882us/step - loss: 0.1834 - acc: 0.9422 - val_loss: 0.2367 - val_acc: 0.9306\n",
      "Epoch 7/20\n",
      "143717/143717 [==============================] - 123s 855us/step - loss: 0.1679 - acc: 0.9482 - val_loss: 0.2176 - val_acc: 0.9369\n",
      "Epoch 8/20\n",
      "143717/143717 [==============================] - 122s 846us/step - loss: 0.1540 - acc: 0.9540 - val_loss: 0.2362 - val_acc: 0.9336\n",
      "Epoch 9/20\n",
      "143717/143717 [==============================] - 122s 849us/step - loss: 0.1438 - acc: 0.9582 - val_loss: 0.1820 - val_acc: 0.9518\n",
      "Epoch 10/20\n",
      "143717/143717 [==============================] - 123s 858us/step - loss: 0.1342 - acc: 0.9627 - val_loss: 0.2468 - val_acc: 0.9313\n",
      "Epoch 11/20\n",
      "143717/143717 [==============================] - 124s 860us/step - loss: 0.1288 - acc: 0.9643 - val_loss: 0.3430 - val_acc: 0.8999\n",
      "Epoch 12/20\n",
      "143717/143717 [==============================] - 135s 939us/step - loss: 0.1209 - acc: 0.9679 - val_loss: 0.2342 - val_acc: 0.9368\n",
      "Epoch 13/20\n",
      "143717/143717 [==============================] - 141s 980us/step - loss: 0.1171 - acc: 0.9687 - val_loss: 0.3004 - val_acc: 0.9160\n",
      "Epoch 14/20\n",
      "143717/143717 [==============================] - 141s 980us/step - loss: 0.1107 - acc: 0.9714 - val_loss: 0.3378 - val_acc: 0.9000\n",
      "Epoch 15/20\n",
      "143717/143717 [==============================] - 132s 916us/step - loss: 0.1082 - acc: 0.9723 - val_loss: 0.2751 - val_acc: 0.9287\n",
      "Epoch 16/20\n",
      "143717/143717 [==============================] - 141s 982us/step - loss: 0.1041 - acc: 0.9741 - val_loss: 0.2980 - val_acc: 0.9207\n",
      "Epoch 17/20\n",
      "143717/143717 [==============================] - 141s 981us/step - loss: 0.1007 - acc: 0.9745 - val_loss: 0.2376 - val_acc: 0.9409\n",
      "Epoch 18/20\n",
      "143717/143717 [==============================] - 141s 983us/step - loss: 0.0970 - acc: 0.9762 - val_loss: 0.2948 - val_acc: 0.9262\n",
      "Epoch 19/20\n",
      "143717/143717 [==============================] - 141s 983us/step - loss: 0.0962 - acc: 0.9765 - val_loss: 0.3723 - val_acc: 0.9014\n",
      "Epoch 20/20\n",
      "143717/143717 [==============================] - 141s 982us/step - loss: 0.0933 - acc: 0.9779 - val_loss: 0.2765 - val_acc: 0.9340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x158ab2da0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_docs, targets, batch_size=512, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "model.save_weights('models/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('models/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comment_to_sequential_input(comment):\n",
    "    tokens = tokenizer[gensim.utils.simple_preprocess(comment)]\n",
    "    t_ids = [corpus_dict.token2id[t] + 1 for t in tokens if t in word2vec.wv.vocab and t in corpus_dict.token2id]\n",
    "    return keras.preprocessing.sequence.pad_sequences([t_ids], maxlen=MAX_SEQ_LEN)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(comment):\n",
    "    test_input = [comment_to_sequential_input(comment).reshape(1, -1)]\n",
    "    for target_class, score in zip(TARGET_CLASSES, model.predict(test_input)[0]):\n",
    "        print(\"{}: {:.2f}%\".format(target_class, score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 67.97%\n"
     ]
    }
   ],
   "source": [
    "comment = \"Why are we having all these people from shit hole countries come here?\"\n",
    "predict(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fucking nutcase ==you're a fucking nutcase\n",
      "toxic: 100.00%\n"
     ]
    }
   ],
   "source": [
    "comment = df.iloc[5].comment\n",
    "print(comment)\n",
    "predict(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 12.44%\n"
     ]
    }
   ],
   "source": [
    "comment = \"Now is the time for all good persons to come to the aid of their country\"\n",
    "predict(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_inputs = np.array([comment_to_sequential_input(doc) for doc in df_test.comment_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_outputs = model.predict_classes(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df = df_test.reset_index()[['id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, target_class in enumerate(TARGET_CLASSES):\n",
    "    output_df[target_class] = test_outputs[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df[output_df.toxic > 0.5].sample(10, random_state=0).merge(df_test.reset_index(), on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df.to_csv('submissions/cnn_0.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(word2vec.vector_size))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(len(TARGET_CLASSES), activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_to_embedding(tokens):\n",
    "    embeddings = [word2vec.wv[t] / word2vec.wv.vocab[t].count for t in tokens if t in word2vec.wv.vocab]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec.vector_size)\n",
    "\n",
    "def text_to_embedding(text):\n",
    "    return tokens_to_embedding(tokenizer[gensim.utils.simple_preprocess(text)])\n",
    "\n",
    "text = 'hello moroccan friend is just a regular message without any insults'\n",
    "model.predict(text_to_embedding(text).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tokens = tokenizer[df_test.comment_text.apply(gensim.utils.simple_preprocess)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = [tokens_to_embedding(tokens) for tokens in test_tokens]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
