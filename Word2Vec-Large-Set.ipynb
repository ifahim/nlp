{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction.\n",
    "\n",
    "These are some (modest) attempts at participating in Jigsaw's toxic comments classification problem. For now, I am not using any external data, only the training data given (which is limiting as it's a tiny dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gensim\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import re\n",
    "import string\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boardgame-comments.csv\r\n",
      "boardgame-frequent-user-comments.csv\r\n",
      "glove.6B.50d.txt\r\n",
      "glove.6B.50d.txt.zip\r\n",
      "sample_submission.csv\r\n",
      "sample_submission.csv.zip\r\n",
      "test.csv\r\n",
      "test.csv.zip\r\n",
      "toxicity_annotated_comments.tsv\r\n",
      "toxicity_annotated_comments_unanimous.tsv\r\n",
      "toxicity_annotations.tsv\r\n",
      "toxicity_annotations_unanimous.tsv\r\n",
      "toxicity_worker_demographics.tsv\r\n",
      "train.csv\r\n",
      "train.csv.zip\r\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/toxicity_annotated_comments.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...  2002   \n",
       "1   4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  \n",
       "0       True  article  random  train  \n",
       "1       True     user  random  train  \n",
       "2      False  article  random   test  \n",
       "3       True  article  random  train  \n",
       "4       True  article  random   test  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159686"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = pd.read_csv('data/toxicity_annotations.tsv',  sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3989</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>1508</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>4020</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id  worker_id  toxicity  toxicity_score\n",
       "0  2232.0        723         0             0.0\n",
       "1  2232.0       4000         0             0.0\n",
       "2  2232.0       3989         0             1.0\n",
       "3  2232.0       3341         0             0.0\n",
       "4  2232.0       1574         0             1.0\n",
       "5  2232.0       1508         0             1.0\n",
       "6  2232.0        772         0             1.0\n",
       "7  2232.0        680         0             0.0\n",
       "8  2232.0        405         0             1.0\n",
       "9  2232.0       4020         1            -1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.drop_duplicates(subset='rev_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159686"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.merge(scores, on='rev_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159686"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>2596</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>1642</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35367.0</td>\n",
       "      <td>`:In an interpreted language your source code ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>1408</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37330.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37346.0</td>\n",
       "      <td>`If they are ``indisputable`` then why does th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37675.0</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44377.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe co...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>1927</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...  2002   \n",
       "1   4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "5  35367.0  `:In an interpreted language your source code ...  2002   \n",
       "6  37330.0  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...  2002   \n",
       "7  37346.0  `If they are ``indisputable`` then why does th...  2002   \n",
       "8  37675.0  `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002   \n",
       "9  44377.0  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe co...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  worker_id  toxicity  toxicity_score  \n",
       "0       True  article  random  train        723         0             0.0  \n",
       "1       True     user  random  train        500         0             0.0  \n",
       "2      False  article  random   test       2596         0             1.0  \n",
       "3       True  article  random  train       1642         0             1.0  \n",
       "4       True  article  random   test        202         0             1.0  \n",
       "5       True  article  random    dev       1408         0             1.0  \n",
       "6       True  article  random  train        691         0             0.0  \n",
       "7       True  article  random  train       1108         0             0.0  \n",
       "8      False  article  random    dev        403         0             1.0  \n",
       "9       True  article  random  train       1927         0             2.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['year', 'logged_in', 'split', 'ns', 'sample'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2596</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>1642</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35367.0</td>\n",
       "      <td>`:In an interpreted language your source code ...</td>\n",
       "      <td>1408</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37330.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...</td>\n",
       "      <td>691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37346.0</td>\n",
       "      <td>`If they are ``indisputable`` then why does th...</td>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37675.0</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44377.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe co...</td>\n",
       "      <td>1927</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  worker_id  \\\n",
       "0   2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...        723   \n",
       "1   4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...        500   \n",
       "2   8953.0                          Elected or Electoral? JHK       2596   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...       1642   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...        202   \n",
       "5  35367.0  `:In an interpreted language your source code ...       1408   \n",
       "6  37330.0  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...        691   \n",
       "7  37346.0  `If they are ``indisputable`` then why does th...       1108   \n",
       "8  37675.0  `-NEWLINE_TOKENThis is not ``creative``.  Thos...        403   \n",
       "9  44377.0  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe co...       1927   \n",
       "\n",
       "   toxicity  toxicity_score  \n",
       "0         0             0.0  \n",
       "1         0             0.0  \n",
       "2         0             1.0  \n",
       "3         0             1.0  \n",
       "4         0             1.0  \n",
       "5         0             1.0  \n",
       "6         0             0.0  \n",
       "7         0             0.0  \n",
       "8         0             1.0  \n",
       "9         0             2.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def mr_clean(comment):\n",
    "    comment = re.sub('NEWLINE_TOKEN', '', comment)\n",
    "    comment = re_tok.sub('', comment)\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment'] = df['comment'].apply(mr_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This    One can make an analogy in mathematica...</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>Clarification for you    and Zundark  s ri...</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral   JHK</td>\n",
       "      <td>2596</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>This is such a fun entry     DevotchkaI once...</td>\n",
       "      <td>1642</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35367.0</td>\n",
       "      <td>In an interpreted language your source cod...</td>\n",
       "      <td>1408</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37330.0</td>\n",
       "      <td>I fixed the link   I also removed     homeop...</td>\n",
       "      <td>691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37346.0</td>\n",
       "      <td>If they are     indisputable     then why do...</td>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37675.0</td>\n",
       "      <td>This is not     creative        Those are ...</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44377.0</td>\n",
       "      <td>The concept of     viral meme     is not a m...</td>\n",
       "      <td>1927</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  worker_id  \\\n",
       "0   2232.0  This    One can make an analogy in mathematica...        723   \n",
       "1   4216.0      Clarification for you    and Zundark  s ri...        500   \n",
       "2   8953.0                         Elected or Electoral   JHK       2596   \n",
       "3  26547.0    This is such a fun entry     DevotchkaI once...       1642   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...        202   \n",
       "5  35367.0      In an interpreted language your source cod...       1408   \n",
       "6  37330.0    I fixed the link   I also removed     homeop...        691   \n",
       "7  37346.0    If they are     indisputable     then why do...       1108   \n",
       "8  37675.0      This is not     creative        Those are ...        403   \n",
       "9  44377.0    The concept of     viral meme     is not a m...       1927   \n",
       "\n",
       "   toxicity  toxicity_score  \n",
       "0         0             0.0  \n",
       "1         0             0.0  \n",
       "2         0             1.0  \n",
       "3         0             1.0  \n",
       "4         0             1.0  \n",
       "5         0             1.0  \n",
       "6         0             0.0  \n",
       "7         0             0.0  \n",
       "8         0             1.0  \n",
       "9         0             2.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['toxic'] = df['toxicity_score'].apply(lambda x: int(x < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['toxicity', 'toxicity_score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(['toxic'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43160</th>\n",
       "      <td>138798055.0</td>\n",
       "      <td>Ck lostsword  s RfA    Thanks         al...</td>\n",
       "      <td>3208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124302</th>\n",
       "      <td>485585361.0</td>\n",
       "      <td>THIS USER IS A PLANT FROM BRUCE PERENS AN...</td>\n",
       "      <td>1236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124227</th>\n",
       "      <td>485198090.0</td>\n",
       "      <td>this Baboon43 is from Scarborough   Toronto  ...</td>\n",
       "      <td>3869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41554</th>\n",
       "      <td>132533129.0</td>\n",
       "      <td>I really do not see how i am acting immature  ...</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124217</th>\n",
       "      <td>485118928.0</td>\n",
       "      <td>Hello BeCritical  Well   I have to say that a...</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124215</th>\n",
       "      <td>485070371.0</td>\n",
       "      <td>fucking nutcase     you  re a fucking nut...</td>\n",
       "      <td>1513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124213</th>\n",
       "      <td>485069083.0</td>\n",
       "      <td>nutcase     you  re a sick bloody nutcase</td>\n",
       "      <td>2939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124212</th>\n",
       "      <td>485068088.0</td>\n",
       "      <td>NUTCASE     YOU  RE A SICK BLOODY NUTCASE</td>\n",
       "      <td>2334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124209</th>\n",
       "      <td>485055520.0</td>\n",
       "      <td>Oh fuck   not Samuel Johnson   Do you have any...</td>\n",
       "      <td>3340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41573</th>\n",
       "      <td>132583618.0</td>\n",
       "      <td>Chinese American Food Society     I recei...</td>\n",
       "      <td>1937</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rev_id                                            comment  \\\n",
       "43160   138798055.0        Ck lostsword  s RfA    Thanks         al...   \n",
       "124302  485585361.0       THIS USER IS A PLANT FROM BRUCE PERENS AN...   \n",
       "124227  485198090.0   this Baboon43 is from Scarborough   Toronto  ...   \n",
       "41554   132533129.0  I really do not see how i am acting immature  ...   \n",
       "124217  485118928.0   Hello BeCritical  Well   I have to say that a...   \n",
       "124215  485070371.0       fucking nutcase     you  re a fucking nut...   \n",
       "124213  485069083.0          nutcase     you  re a sick bloody nutcase   \n",
       "124212  485068088.0          NUTCASE     YOU  RE A SICK BLOODY NUTCASE   \n",
       "124209  485055520.0  Oh fuck   not Samuel Johnson   Do you have any...   \n",
       "41573   132583618.0       Chinese American Food Society     I recei...   \n",
       "\n",
       "        worker_id  toxic  \n",
       "43160        3208      1  \n",
       "124302       1236      1  \n",
       "124227       3869      1  \n",
       "41554         144      1  \n",
       "124217         24      1  \n",
       "124215       1513      1  \n",
       "124213       2939      1  \n",
       "124212       2334      1  \n",
       "124209       3340      1  \n",
       "41573        1937      1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_tokens = df.comment.apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrases = gensim.models.phrases.Phrases(simple_tokens)\n",
    "tokenizer = gensim.models.phrases.Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_text = list(tokenizer[simple_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ck',\n",
       " 'lostsword',\n",
       " 'rfa',\n",
       " 'thanks',\n",
       " 'align_center',\n",
       " 'width_style',\n",
       " 'border',\n",
       " 'ff',\n",
       " 'solid',\n",
       " 'px_moz',\n",
       " 'border_radius',\n",
       " 'px',\n",
       " 'background',\n",
       " 'ebebeb',\n",
       " 'text_align',\n",
       " 'left',\n",
       " 'color_ff',\n",
       " 'padding_px',\n",
       " 'rowspan',\n",
       " 'thanks',\n",
       " 'very_much',\n",
       " 'for',\n",
       " 'your',\n",
       " 'support',\n",
       " 'in',\n",
       " 'my',\n",
       " 'recent_rfa',\n",
       " 'which',\n",
       " 'passed',\n",
       " 'successfully',\n",
       " 'at',\n",
       " 'making',\n",
       " 'me',\n",
       " 'wikipedia',\n",
       " 'th',\n",
       " 'administrator',\n",
       " 'your',\n",
       " 'comments',\n",
       " 'were',\n",
       " 'much_appreciated',\n",
       " 'and',\n",
       " 'will',\n",
       " 'endeavour',\n",
       " 'to',\n",
       " 'fulfil',\n",
       " 'your',\n",
       " 'expectations',\n",
       " 'as',\n",
       " 'an_admin']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_dict = gensim.corpora.dictionary.Dictionary(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rev_id', 'comment', 'worker_id', 'toxic'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET_CLASSES = ['toxic']\n",
    "targets = df[TARGET_CLASSES].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ..., \n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 400)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1481dceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot([len(doc) for doc in tokenized_text], bins=100, kde=False, label='Number of tokens per comment.')\n",
    "plt.xlabel(\"Tokens in a comment\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim((0, 400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training word2vec on comment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = gensim.models.word2vec.Word2Vec(tokenized_text, window=5, size=100, min_count=2, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reference', 0.8243365287780762),\n",
       " ('source', 0.7994678616523743),\n",
       " ('citations', 0.772555410861969),\n",
       " ('verification', 0.7714164853096008),\n",
       " ('footnote', 0.760730504989624),\n",
       " ('references', 0.750859797000885),\n",
       " ('secondary_source', 0.7351768612861633),\n",
       " ('ref', 0.7213565707206726),\n",
       " ('reliable_source', 0.7117491960525513),\n",
       " ('quotation', 0.6953125596046448)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar('citation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dumb', 0.8174044489860535),\n",
       " ('silly', 0.7564979791641235),\n",
       " ('crazy', 0.7542504072189331),\n",
       " ('pathetic', 0.7465818524360657),\n",
       " ('retarded', 0.746462881565094),\n",
       " ('funny', 0.742946445941925),\n",
       " ('lazy', 0.71101975440979),\n",
       " ('annoying', 0.6992161273956299),\n",
       " ('ugly', 0.6969090700149536),\n",
       " ('bad', 0.691879153251648)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar('stupid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec-based model\n",
    "\n",
    "Aggregate word embeddings per comment (~ tf-idf weighted averaging), and use that as an input feature in a neural net with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.zeros((len(tokenized_text), word2vec.vector_size))\n",
    "for i, tokens in enumerate(tokenized_text):\n",
    "    tokens = [t for t in tokens if t in word2vec.wv.vocab]\n",
    "    if tokens:\n",
    "        features[i, :] = np.mean([word2vec.wv[t] / word2vec.wv.vocab[t].count for t in tokens], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "#model.add(Dense(256, activation='relu', input_shape=(word2vec.vector_size,)))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(len(TARGET_CLASSES), activation='sigmoid'))\n",
    "#model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(features, targets, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential models\n",
    "\n",
    "Simply averaging embeddings across all terms in a comment loses interactions that can occur between words, and the importance of their position. Because of this, we will now experiment with position-aware models: LSTM and CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: shifting indices by 1 as index 0 will be used for padding.\n",
    "docs = [[idx + 1 for idx in corpus_dict.doc2idx(doc)]  for doc in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 50\n",
    "padded_docs = keras.preprocessing.sequence.pad_sequences(docs, maxlen=MAX_SEQ_LEN, truncating='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190958"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idx = max(c for d in docs for c in d)\n",
    "max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = np.array([np.random.normal(size=word2vec.vector_size)]+ # for the '0' padding word\n",
    "                      [word2vec.wv[corpus_dict[idx]]\n",
    "                      if corpus_dict[idx] in word2vec.wv.vocab\n",
    "                      else np.random.normal(size=word2vec.vector_size)\n",
    "                      for idx in range(max_idx)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import Convolution1D, MaxPool1D, Flatten, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_idx + 1, word2vec.vector_size, input_length=MAX_SEQ_LEN))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution1D(52, 5, padding='same',\n",
    "                        kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "model.add(MaxPool1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution1D(128, 3, padding='same',\n",
    "                        kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "model.add(MaxPool1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(TARGET_CLASSES), activation='sigmoid',\n",
    "                kernel_regularizer=keras.regularizers.l2(0.02)))\n",
    "model.compile(Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143717 samples, validate on 15969 samples\n",
      "Epoch 1/20\n",
      "143717/143717 [==============================] - 124s 863us/step - loss: 0.7245 - acc: 0.8573 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "143717/143717 [==============================] - 122s 852us/step - loss: 0.3070 - acc: 0.8928 - val_loss: 0.0772 - val_acc: 0.9975\n",
      "Epoch 3/20\n",
      "143717/143717 [==============================] - 130s 904us/step - loss: 0.2573 - acc: 0.9096 - val_loss: 0.0969 - val_acc: 0.9857\n",
      "Epoch 4/20\n",
      "143717/143717 [==============================] - 129s 899us/step - loss: 0.2283 - acc: 0.9216 - val_loss: 0.1442 - val_acc: 0.9679\n",
      "Epoch 5/20\n",
      "143717/143717 [==============================] - 123s 854us/step - loss: 0.2037 - acc: 0.9328 - val_loss: 0.1250 - val_acc: 0.9726\n",
      "Epoch 6/20\n",
      "143717/143717 [==============================] - 130s 907us/step - loss: 0.1832 - acc: 0.9422 - val_loss: 0.2231 - val_acc: 0.9347\n",
      "Epoch 7/20\n",
      "143717/143717 [==============================] - 125s 869us/step - loss: 0.1674 - acc: 0.9492 - val_loss: 0.1826 - val_acc: 0.9505\n",
      "Epoch 8/20\n",
      "143717/143717 [==============================] - 123s 854us/step - loss: 0.1530 - acc: 0.9547 - val_loss: 0.2001 - val_acc: 0.9485\n",
      "Epoch 9/20\n",
      "143717/143717 [==============================] - 122s 851us/step - loss: 0.1431 - acc: 0.9590 - val_loss: 0.2257 - val_acc: 0.9367\n",
      "Epoch 10/20\n",
      "143717/143717 [==============================] - 122s 851us/step - loss: 0.1340 - acc: 0.9629 - val_loss: 0.2211 - val_acc: 0.9394\n",
      "Epoch 11/20\n",
      "143717/143717 [==============================] - 112s 779us/step - loss: 0.1278 - acc: 0.9654 - val_loss: 0.2485 - val_acc: 0.9303\n",
      "Epoch 12/20\n",
      "143717/143717 [==============================] - 123s 853us/step - loss: 0.1209 - acc: 0.9679 - val_loss: 0.2104 - val_acc: 0.9455\n",
      "Epoch 13/20\n",
      "143717/143717 [==============================] - 122s 847us/step - loss: 0.1169 - acc: 0.9694 - val_loss: 0.2358 - val_acc: 0.9377\n",
      "Epoch 14/20\n",
      "143717/143717 [==============================] - 123s 856us/step - loss: 0.1119 - acc: 0.9715 - val_loss: 0.2387 - val_acc: 0.9346\n",
      "Epoch 15/20\n",
      "143717/143717 [==============================] - 122s 846us/step - loss: 0.1070 - acc: 0.9734 - val_loss: 0.2154 - val_acc: 0.9432\n",
      "Epoch 16/20\n",
      "143717/143717 [==============================] - 122s 849us/step - loss: 0.1033 - acc: 0.9744 - val_loss: 0.3108 - val_acc: 0.9204\n",
      "Epoch 17/20\n",
      "143717/143717 [==============================] - 126s 877us/step - loss: 0.1012 - acc: 0.9750 - val_loss: 0.2885 - val_acc: 0.9232\n",
      "Epoch 18/20\n",
      "143717/143717 [==============================] - 122s 846us/step - loss: 0.0985 - acc: 0.9760 - val_loss: 0.2927 - val_acc: 0.9227\n",
      "Epoch 19/20\n",
      "143717/143717 [==============================] - 121s 845us/step - loss: 0.0964 - acc: 0.9765 - val_loss: 0.3123 - val_acc: 0.9124\n",
      "Epoch 20/20\n",
      "143717/143717 [==============================] - 116s 806us/step - loss: 0.0925 - acc: 0.9782 - val_loss: 0.2710 - val_acc: 0.9327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ce96d68>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_docs, targets, batch_size=512, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('models/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comment_to_sequential_input(comment):\n",
    "    tokens = tokenizer[gensim.utils.simple_preprocess(comment)]\n",
    "    t_ids = [corpus_dict.token2id[t] + 1 for t in tokens if t in word2vec.wv.vocab and t in corpus_dict.token2id]\n",
    "    return keras.preprocessing.sequence.pad_sequences([t_ids], maxlen=MAX_SEQ_LEN)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(comment):\n",
    "    test_input = [comment_to_sequential_input(comment).reshape(1, -1)]\n",
    "    for target_class, score in zip(TARGET_CLASSES, model.predict(test_input)[0]):\n",
    "        print(\"{}: {:.2f}%\".format(target_class, score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 32.29%\n"
     ]
    }
   ],
   "source": [
    "comment = \"Why are we having all these people from shit hole countries come here?\"\n",
    "predict(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fucking nutcase     you  re a fucking nutcase\n",
      "toxic: 100.00%\n"
     ]
    }
   ],
   "source": [
    "comment = df.iloc[5].comment\n",
    "print(comment)\n",
    "predict(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 1.28%\n"
     ]
    }
   ],
   "source": [
    "comment = \"Now is the time for all good persons to come to the aid of their country\"\n",
    "predict(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = np.array([comment_to_sequential_input(doc) for doc in df.comment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df.as_matrix(columns=['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93754618438685922"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      toxic       0.95      0.98      0.96    136339\n",
      "\n",
      "avg / total       0.94      0.94      0.94    159686\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbatz/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 2, does not match size of target_names, 1\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "target_names = ['toxic']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df = df_test.reset_index()[['id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, target_class in enumerate(TARGET_CLASSES):\n",
    "    output_df[target_class] = test_outputs[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df[output_df.toxic > 0.5].sample(10, random_state=0).merge(df_test.reset_index(), on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df.to_csv('submissions/cnn_0.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(word2vec.vector_size))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(len(TARGET_CLASSES), activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_to_embedding(tokens):\n",
    "    embeddings = [word2vec.wv[t] / word2vec.wv.vocab[t].count for t in tokens if t in word2vec.wv.vocab]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec.vector_size)\n",
    "\n",
    "def text_to_embedding(text):\n",
    "    return tokens_to_embedding(tokenizer[gensim.utils.simple_preprocess(text)])\n",
    "\n",
    "text = 'hello moroccan friend is just a regular message without any insults'\n",
    "model.predict(text_to_embedding(text).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tokens = tokenizer[df_test.comment_text.apply(gensim.utils.simple_preprocess)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = [tokens_to_embedding(tokens) for tokens in test_tokens]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
